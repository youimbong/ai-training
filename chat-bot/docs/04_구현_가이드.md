# AI ì±—ë´‡ êµ¬í˜„ ê°€ì´ë“œ

## 1. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
chat-bot/
â”œâ”€â”€ streamlit_app.py           # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”œâ”€â”€ requirements.txt            # í”„ë¡œì íŠ¸ ì˜ì¡´ì„±
â”œâ”€â”€ .env                       # í™˜ê²½ ë³€ìˆ˜ (API í‚¤ ë“±)
â”œâ”€â”€ .gitignore                 # Git ì œì™¸ íŒŒì¼
â”œâ”€â”€ Dockerfile                 # Docker ì»¨í…Œì´ë„ˆ ì„¤ì •
â”œâ”€â”€ docker-compose.yml         # Docker Compose ì„¤ì •
â”‚
â”œâ”€â”€ src/                       # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                  # í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ session_manager.py
â”‚   â”‚   â”œâ”€â”€ conversation_manager.py
â”‚   â”‚   â””â”€â”€ message_processor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/              # ì™¸ë¶€ ì„œë¹„ìŠ¤ í†µí•©
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ai_service.py
â”‚   â”‚   â”œâ”€â”€ openai_service.py
â”‚   â”‚   â”œâ”€â”€ claude_service.py
â”‚   â”‚   â””â”€â”€ cache_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ message.py
â”‚   â”‚   â””â”€â”€ conversation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                    # UI ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat_interface.py
â”‚   â”‚   â”œâ”€â”€ sidebar.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                 # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ validators.py
â”‚   â”‚   â”œâ”€â”€ encryption.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”‚
â”‚   â””â”€â”€ db/                    # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ connection.py
â”‚       â”œâ”€â”€ migrations/
â”‚       â””â”€â”€ queries.py
â”‚
â”œâ”€â”€ tests/                     # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_services/
â”‚   â”œâ”€â”€ test_core/
â”‚   â””â”€â”€ test_ui/
â”‚
â”œâ”€â”€ docs/                      # ë¬¸ì„œ
â”‚   â”œâ”€â”€ 01_ì‹œìŠ¤í…œ_ì•„í‚¤í…ì²˜_ì„¤ê³„.md
â”‚   â”œâ”€â”€ 02_API_ì¸í„°í˜ì´ìŠ¤_ì„¤ê³„.md
â”‚   â”œâ”€â”€ 03_ë°ì´í„°_ëª¨ë¸_ì„¤ê³„.md
â”‚   â””â”€â”€ 04_êµ¬í˜„_ê°€ì´ë“œ.md
â”‚
â”œâ”€â”€ config/                    # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ logging.yaml
â”‚
â””â”€â”€ scripts/                   # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ setup.sh
    â”œâ”€â”€ deploy.sh
    â””â”€â”€ backup.py
```

## 2. í™˜ê²½ ì„¤ì •

### 2.1 í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# requirements.txt
streamlit==1.31.0
openai==1.12.0
anthropic==0.18.0
python-dotenv==1.0.0
pydantic==2.5.0
sqlalchemy==2.0.25
aiosqlite==0.19.0
redis==5.0.1
cryptography==42.0.0
pytest==8.0.0
pytest-asyncio==0.23.0
black==24.1.0
ruff==0.2.0
```

### 2.2 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env
# API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Database
DATABASE_URL=sqlite+aiosqlite:///./chatbot.db
REDIS_URL=redis://localhost:6379

# Security
ENCRYPTION_KEY=your-encryption-key-here
SECRET_KEY=your-secret-key-here

# App Config
APP_ENV=development
LOG_LEVEL=INFO
MAX_TOKENS=4000
DEFAULT_MODEL=gpt-3.5-turbo
```

## 3. í•µì‹¬ êµ¬í˜„ ì½”ë“œ

### 3.1 ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (streamlit_app.py)

```python
import streamlit as st
import asyncio
from dotenv import load_dotenv
import sys
import os

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from src.core.session_manager import SessionManager
from src.core.conversation_manager import ConversationManager
from src.services.ai_service import AIServiceFactory
from src.ui.chat_interface import ChatInterface
from src.ui.sidebar import Sidebar
from src.utils.logger import setup_logger

# ë¡œê±° ì„¤ì •
logger = setup_logger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    .stChat {
        max-width: 1200px;
        margin: 0 auto;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 10px;
        border-radius: 10px;
        margin: 5px 0;
    }
    .assistant-message {
        background-color: #f5f5f5;
        padding: 10px;
        border-radius: 10px;
        margin: 5px 0;
    }
    </style>
""", unsafe_allow_html=True)

class ChatbotApp:
    """ë©”ì¸ ì±—ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self):
        self.session_manager = SessionManager()
        self.conversation_manager = ConversationManager()
        self.ai_service = None
        self.chat_interface = ChatInterface()
        self.sidebar = Sidebar()
        
    def initialize_session(self):
        """ì„¸ì…˜ ì´ˆê¸°í™”"""
        if 'session_id' not in st.session_state:
            session = self.session_manager.create_session()
            st.session_state.session_id = session.session_id
            st.session_state.messages = []
            st.session_state.current_model = os.getenv("DEFAULT_MODEL", "gpt-3.5-turbo")
            st.session_state.settings = {
                "temperature": 0.7,
                "max_tokens": 2000,
                "stream": True
            }
            logger.info(f"New session created: {session.session_id}")
    
    async def process_message(self, user_input: str):
        """ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            user_message = await self.conversation_manager.add_user_message(
                st.session_state.session_id,
                user_input
            )
            st.session_state.messages.append(user_message)
            
            # AI ì‘ë‹µ ìƒì„±
            with st.spinner("ìƒê° ì¤‘..."):
                if st.session_state.settings.get("stream", True):
                    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    async for chunk in self.ai_service.stream_response(
                        messages=st.session_state.messages,
                        settings=st.session_state.settings
                    ):
                        full_response += chunk
                        response_placeholder.markdown(full_response)
                    
                    assistant_message = await self.conversation_manager.add_assistant_message(
                        st.session_state.session_id,
                        full_response
                    )
                else:
                    # ì¼ë°˜ ì‘ë‹µ
                    response = await self.ai_service.generate_response(
                        messages=st.session_state.messages,
                        settings=st.session_state.settings
                    )
                    assistant_message = response
                    st.markdown(response.content)
            
            st.session_state.messages.append(assistant_message)
            
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        # ì„¸ì…˜ ì´ˆê¸°í™”
        self.initialize_session()
        
        # íƒ€ì´í‹€
        st.title("ğŸ¤– AI ì±—ë´‡")
        st.caption("AIì™€ ëŒ€í™”ë¥¼ ë‚˜ëˆ ë³´ì„¸ìš”!")
        
        # ì‚¬ì´ë“œë°” ë Œë”ë§
        model_type, settings = self.sidebar.render()
        
        if model_type != st.session_state.current_model:
            st.session_state.current_model = model_type
            self.ai_service = AIServiceFactory.create(model_type)
            st.rerun()
        
        st.session_state.settings.update(settings)
        
        # AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        if not self.ai_service:
            self.ai_service = AIServiceFactory.create(st.session_state.current_model)
        
        # ëŒ€í™” ë‚´ì—­ í‘œì‹œ
        self.chat_interface.render_conversation(st.session_state.messages)
        
        # ì…ë ¥ ì˜ì—­
        user_input = self.chat_interface.render_input_area()
        
        if user_input:
            # ë¹„ë™ê¸° ì²˜ë¦¬
            asyncio.run(self.process_message(user_input))
            st.rerun()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    app = ChatbotApp()
    app.run()

if __name__ == "__main__":
    main()
```

### 3.2 AI ì„œë¹„ìŠ¤ êµ¬í˜„

```python
# src/services/ai_service.py
from abc import ABC, abstractmethod
from typing import List, Dict, Generator, Optional
import os
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic

class AIService(ABC):
    """AI ì„œë¹„ìŠ¤ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def generate_response(
        self, 
        messages: List[Dict],
        settings: Dict
    ) -> str:
        """ì‘ë‹µ ìƒì„±"""
        pass
    
    @abstractmethod
    async def stream_response(
        self,
        messages: List[Dict],
        settings: Dict
    ) -> Generator[str, None, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        pass

class OpenAIService(AIService):
    """OpenAI ì„œë¹„ìŠ¤ êµ¬í˜„"""
    
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        )
    
    async def generate_response(
        self, 
        messages: List[Dict],
        settings: Dict
    ) -> str:
        """OpenAI ì‘ë‹µ ìƒì„±"""
        response = await self.client.chat.completions.create(
            model=settings.get("model", "gpt-3.5-turbo"),
            messages=messages,
            temperature=settings.get("temperature", 0.7),
            max_tokens=settings.get("max_tokens", 2000)
        )
        return response.choices[0].message.content
    
    async def stream_response(
        self,
        messages: List[Dict],
        settings: Dict
    ) -> Generator[str, None, None]:
        """OpenAI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
        stream = await self.client.chat.completions.create(
            model=settings.get("model", "gpt-3.5-turbo"),
            messages=messages,
            temperature=settings.get("temperature", 0.7),
            max_tokens=settings.get("max_tokens", 2000),
            stream=True
        )
        
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content

class ClaudeService(AIService):
    """Claude ì„œë¹„ìŠ¤ êµ¬í˜„"""
    
    def __init__(self):
        self.client = AsyncAnthropic(
            api_key=os.getenv("ANTHROPIC_API_KEY")
        )
    
    async def generate_response(
        self, 
        messages: List[Dict],
        settings: Dict
    ) -> str:
        """Claude ì‘ë‹µ ìƒì„±"""
        response = await self.client.messages.create(
            model=settings.get("model", "claude-3-sonnet-20240229"),
            messages=messages,
            max_tokens=settings.get("max_tokens", 2000),
            temperature=settings.get("temperature", 0.7)
        )
        return response.content[0].text
    
    async def stream_response(
        self,
        messages: List[Dict],
        settings: Dict
    ) -> Generator[str, None, None]:
        """Claude ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
        async with self.client.messages.stream(
            model=settings.get("model", "claude-3-sonnet-20240229"),
            messages=messages,
            max_tokens=settings.get("max_tokens", 2000),
            temperature=settings.get("temperature", 0.7)
        ) as stream:
            async for text in stream.text_stream:
                yield text

class AIServiceFactory:
    """AI ì„œë¹„ìŠ¤ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create(model_type: str) -> AIService:
        """ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ ì„œë¹„ìŠ¤ ìƒì„±"""
        if model_type.startswith("gpt"):
            return OpenAIService()
        elif model_type.startswith("claude"):
            return ClaudeService()
        else:
            raise ValueError(f"Unsupported model type: {model_type}")
```

### 3.3 UI ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

```python
# src/ui/chat_interface.py
import streamlit as st
from typing import List, Dict

class ChatInterface:
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì»´í¬ë„ŒíŠ¸"""
    
    def render_conversation(self, messages: List[Dict]):
        """ëŒ€í™” ë‚´ì—­ ë Œë”ë§"""
        for message in messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    def render_input_area(self) -> str:
        """ì…ë ¥ ì˜ì—­ ë Œë”ë§"""
        return st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    
    def render_typing_indicator(self):
        """íƒ€ì´í•‘ ì¸ë””ì¼€ì´í„°"""
        with st.chat_message("assistant"):
            st.markdown("ğŸ’­ ìƒê° ì¤‘...")

# src/ui/sidebar.py
import streamlit as st
from typing import Tuple, Dict

class Sidebar:
    """ì‚¬ì´ë“œë°” ì»´í¬ë„ŒíŠ¸"""
    
    def render(self) -> Tuple[str, Dict]:
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.header("âš™ï¸ ì„¤ì •")
            
            # ëª¨ë¸ ì„ íƒ
            model = st.selectbox(
                "AI ëª¨ë¸",
                ["gpt-3.5-turbo", "gpt-4", "claude-3-sonnet", "claude-3-opus"],
                index=0
            )
            
            # ê³ ê¸‰ ì„¤ì •
            with st.expander("ê³ ê¸‰ ì„¤ì •"):
                temperature = st.slider(
                    "Temperature",
                    min_value=0.0,
                    max_value=2.0,
                    value=0.7,
                    step=0.1
                )
                
                max_tokens = st.number_input(
                    "Max Tokens",
                    min_value=100,
                    max_value=4000,
                    value=2000,
                    step=100
                )
                
                stream = st.checkbox("ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ", value=True)
            
            # ëŒ€í™” ê´€ë¦¬
            st.divider()
            st.header("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
            
            if st.button("ìƒˆ ëŒ€í™” ì‹œì‘", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
            
            if st.button("ëŒ€í™” ë‚´ì—­ ì €ì¥", use_container_width=True):
                # TODO: êµ¬í˜„
                st.success("ëŒ€í™”ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            if st.button("ëŒ€í™” ë‚´ì—­ ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True):
                # TODO: êµ¬í˜„
                pass
            
            settings = {
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": stream
            }
            
            return model, settings
```

## 4. ë°°í¬ ë°©ë²•

### 4.1 ë¡œì»¬ ë°°í¬

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì— API í‚¤ ì…ë ¥

# 4. ì‹¤í–‰
streamlit run streamlit_app.py
```

### 4.2 Docker ë°°í¬

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8501

# ì‹¤í–‰ ëª…ë ¹
CMD ["streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  chatbot:
    build: .
    ports:
      - "8501:8501"
    env_file:
      - .env
    volumes:
      - ./data:/app/data
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

volumes:
  redis_data:
```

### 4.3 Streamlit Cloud ë°°í¬

1. GitHub ì €ì¥ì†Œ ìƒì„± ë° ì½”ë“œ í‘¸ì‹œ
2. [share.streamlit.io](https://share.streamlit.io) ì ‘ì†
3. GitHub ì €ì¥ì†Œ ì—°ê²°
4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (Secrets)
5. ë°°í¬

### 4.4 Heroku ë°°í¬

```bash
# 1. Heroku CLI ì„¤ì¹˜
# 2. Procfile ìƒì„±
echo "web: sh setup.sh && streamlit run streamlit_app.py" > Procfile

# 3. setup.sh ìƒì„±
cat > setup.sh << 'EOF'
mkdir -p ~/.streamlit/

echo "\
[general]\n\
email = \"your-email@domain.com\"\n\
" > ~/.streamlit/credentials.toml

echo "\
[server]\n\
headless = true\n\
enableCORS=false\n\
port = $PORT\n\
" > ~/.streamlit/config.toml
EOF

# 4. Heroku ì•± ìƒì„± ë° ë°°í¬
heroku create your-chatbot-app
heroku config:set OPENAI_API_KEY=your-key
git push heroku main
```

## 5. ì„±ëŠ¥ ìµœì í™”

### 5.1 ìºì‹± êµ¬í˜„

```python
import streamlit as st
from functools import lru_cache
import hashlib

@st.cache_data(ttl=3600)
def get_cached_response(prompt_hash: str) -> str:
    """ìºì‹œëœ ì‘ë‹µ ì¡°íšŒ"""
    # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìºì‹œ ì¡°íšŒ
    pass

@lru_cache(maxsize=100)
def calculate_prompt_hash(prompt: str) -> str:
    """í”„ë¡¬í”„íŠ¸ í•´ì‹œ ê³„ì‚°"""
    return hashlib.md5(prompt.encode()).hexdigest()
```

### 5.2 ë¹„ë™ê¸° ì²˜ë¦¬

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor(max_workers=4)

async def process_batch_messages(messages: List[str]):
    """ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬"""
    tasks = [process_single_message(msg) for msg in messages]
    return await asyncio.gather(*tasks)
```

## 6. í…ŒìŠ¤íŠ¸

### 6.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/test_services/test_ai_service.py
import pytest
from unittest.mock import Mock, AsyncMock
from src.services.ai_service import OpenAIService

@pytest.mark.asyncio
async def test_generate_response():
    """ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸"""
    service = OpenAIService()
    service.client = Mock()
    service.client.chat.completions.create = AsyncMock(
        return_value=Mock(
            choices=[Mock(message=Mock(content="Test response"))]
        )
    )
    
    response = await service.generate_response(
        messages=[{"role": "user", "content": "Hello"}],
        settings={"model": "gpt-3.5-turbo"}
    )
    
    assert response == "Test response"
```

### 6.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/test_integration.py
import pytest
from streamlit.testing.v1 import AppTest

def test_chatbot_app():
    """ì±—ë´‡ ì•± í†µí•© í…ŒìŠ¤íŠ¸"""
    at = AppTest.from_file("streamlit_app.py")
    at.run()
    
    # ì´ˆê¸° ìƒíƒœ í™•ì¸
    assert not at.exception
    assert at.title[0].value == "ğŸ¤– AI ì±—ë´‡"
    
    # ë©”ì‹œì§€ ì…ë ¥ í…ŒìŠ¤íŠ¸
    at.chat_input[0].set_value("Hello").run()
    assert len(at.chat_message) > 0
```

## 7. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 7.1 ë¡œê¹… ì„¤ì •

```python
# src/utils/logger.py
import logging
import sys
from logging.handlers import RotatingFileHandler

def setup_logger(name: str) -> logging.Logger:
    """ë¡œê±° ì„¤ì •"""
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler(sys.stdout)
    console_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(console_formatter)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    file_handler = RotatingFileHandler(
        'chatbot.log',
        maxBytes=10485760,  # 10MB
        backupCount=5
    )
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
    )
    file_handler.setFormatter(file_formatter)
    
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    
    return logger
```

## 8. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 8.1 API í‚¤ ê´€ë¦¬

```python
# src/utils/encryption.py
from cryptography.fernet import Fernet
import os

class SecureStorage:
    """ë³´ì•ˆ ì €ì¥ì†Œ"""
    
    def __init__(self):
        key = os.getenv("ENCRYPTION_KEY")
        if not key:
            key = Fernet.generate_key()
        self.cipher = Fernet(key)
    
    def encrypt_api_key(self, api_key: str) -> bytes:
        """API í‚¤ ì•”í˜¸í™”"""
        return self.cipher.encrypt(api_key.encode())
    
    def decrypt_api_key(self, encrypted_key: bytes) -> str:
        """API í‚¤ ë³µí˜¸í™”"""
        return self.cipher.decrypt(encrypted_key).decode()
```

### 8.2 ì…ë ¥ ê²€ì¦

```python
# src/utils/validators.py
import re
from typing import Tuple

def validate_user_input(text: str) -> Tuple[bool, str]:
    """ì‚¬ìš©ì ì…ë ¥ ê²€ì¦"""
    # ê¸¸ì´ ì²´í¬
    if len(text) > 10000:
        return False, "ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤."
    
    # XSS ë°©ì§€
    if re.search(r'<script|javascript:', text, re.IGNORECASE):
        return False, "í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    
    # SQL ì¸ì ì…˜ ë°©ì§€
    if re.search(r"(DROP|DELETE|INSERT|UPDATE)\s+", text, re.IGNORECASE):
        return False, "í—ˆìš©ë˜ì§€ ì•ŠëŠ” SQL ëª…ë ¹ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    
    return True, ""
```

## 9. í™•ì¥ ê¸°ëŠ¥

### 9.1 RAG (Retrieval-Augmented Generation) ì§€ì›

```python
# src/services/rag_service.py
from typing import List
import chromadb

class RAGService:
    """RAG ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.client = chromadb.Client()
        self.collection = self.client.create_collection("documents")
    
    async def add_document(self, text: str, metadata: dict):
        """ë¬¸ì„œ ì¶”ê°€"""
        embedding = await self.generate_embedding(text)
        self.collection.add(
            embeddings=[embedding],
            documents=[text],
            metadatas=[metadata]
        )
    
    async def search_similar(self, query: str, n_results: int = 5):
        """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
        query_embedding = await self.generate_embedding(query)
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )
        return results
```

### 9.2 ë‹¤êµ­ì–´ ì§€ì›

```python
# src/utils/i18n.py
translations = {
    "ko": {
        "welcome": "AI ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!",
        "enter_message": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
        "settings": "ì„¤ì •",
        "new_chat": "ìƒˆ ëŒ€í™” ì‹œì‘"
    },
    "en": {
        "welcome": "Welcome to AI Chatbot!",
        "enter_message": "Enter your message...",
        "settings": "Settings",
        "new_chat": "Start New Chat"
    }
}

def get_text(key: str, lang: str = "ko") -> str:
    """ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    return translations.get(lang, {}).get(key, key)
```

## 10. ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### 10.1 ì¼ë°˜ì ì¸ ë¬¸ì œ

| ë¬¸ì œ | ì›ì¸ | í•´ê²° ë°©ë²• |
|------|------|-----------|
| API í‚¤ ì˜¤ë¥˜ | ì˜ëª»ëœ í‚¤ ë˜ëŠ” ë§Œë£Œ | .env íŒŒì¼ í™•ì¸ ë° í‚¤ ì¬ë°œê¸‰ |
| ëŠë¦° ì‘ë‹µ | ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ëª¨ë¸ ì´ìŠˆ | ìºì‹± í™œì„±í™”, ëª¨ë¸ ë³€ê²½ |
| ì„¸ì…˜ ì†ì‹¤ | ì„œë²„ ì¬ì‹œì‘ | Redis ë“± ì˜êµ¬ ì €ì¥ì†Œ ì‚¬ìš© |
| ë©”ëª¨ë¦¬ ë¶€ì¡± | ëŒ€í™” ë‚´ì—­ ê³¼ë‹¤ | ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œ |

### 10.2 ë””ë²„ê¹… íŒ

```python
# ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”
if os.getenv("APP_ENV") == "development":
    st.sidebar.json(st.session_state)  # ì„¸ì…˜ ìƒíƒœ í‘œì‹œ
    
# ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()
# ì½”ë“œ ì‹¤í–‰
profiler.disable()
stats = pstats.Stats(profiler)
stats.print_stats()
```