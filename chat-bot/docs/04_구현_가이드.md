# AI 챗봇 구현 가이드

## 1. 프로젝트 구조

```
chat-bot/
├── streamlit_app.py           # 메인 애플리케이션 진입점
├── requirements.txt            # 프로젝트 의존성
├── .env                       # 환경 변수 (API 키 등)
├── .gitignore                 # Git 제외 파일
├── Dockerfile                 # Docker 컨테이너 설정
├── docker-compose.yml         # Docker Compose 설정
│
├── src/                       # 소스 코드
│   ├── __init__.py
│   ├── core/                  # 핵심 비즈니스 로직
│   │   ├── __init__.py
│   │   ├── session_manager.py
│   │   ├── conversation_manager.py
│   │   └── message_processor.py
│   │
│   ├── services/              # 외부 서비스 통합
│   │   ├── __init__.py
│   │   ├── ai_service.py
│   │   ├── openai_service.py
│   │   ├── claude_service.py
│   │   └── cache_service.py
│   │
│   ├── models/                # 데이터 모델
│   │   ├── __init__.py
│   │   ├── session.py
│   │   ├── message.py
│   │   └── conversation.py
│   │
│   ├── ui/                    # UI 컴포넌트
│   │   ├── __init__.py
│   │   ├── chat_interface.py
│   │   ├── sidebar.py
│   │   └── settings.py
│   │
│   ├── utils/                 # 유틸리티 함수
│   │   ├── __init__.py
│   │   ├── validators.py
│   │   ├── encryption.py
│   │   └── logger.py
│   │
│   └── db/                    # 데이터베이스 관련
│       ├── __init__.py
│       ├── connection.py
│       ├── migrations/
│       └── queries.py
│
├── tests/                     # 테스트 코드
│   ├── __init__.py
│   ├── test_services/
│   ├── test_core/
│   └── test_ui/
│
├── docs/                      # 문서
│   ├── 01_시스템_아키텍처_설계.md
│   ├── 02_API_인터페이스_설계.md
│   ├── 03_데이터_모델_설계.md
│   └── 04_구현_가이드.md
│
├── config/                    # 설정 파일
│   ├── config.yaml
│   └── logging.yaml
│
└── scripts/                   # 유틸리티 스크립트
    ├── setup.sh
    ├── deploy.sh
    └── backup.py
```

## 2. 환경 설정

### 2.1 필수 패키지 설치

```bash
# requirements.txt
streamlit==1.31.0
openai==1.12.0
anthropic==0.18.0
python-dotenv==1.0.0
pydantic==2.5.0
sqlalchemy==2.0.25
aiosqlite==0.19.0
redis==5.0.1
cryptography==42.0.0
pytest==8.0.0
pytest-asyncio==0.23.0
black==24.1.0
ruff==0.2.0
```

### 2.2 환경 변수 설정

```bash
# .env
# API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Database
DATABASE_URL=sqlite+aiosqlite:///./chatbot.db
REDIS_URL=redis://localhost:6379

# Security
ENCRYPTION_KEY=your-encryption-key-here
SECRET_KEY=your-secret-key-here

# App Config
APP_ENV=development
LOG_LEVEL=INFO
MAX_TOKENS=4000
DEFAULT_MODEL=gpt-3.5-turbo
```

## 3. 핵심 구현 코드

### 3.1 메인 애플리케이션 (streamlit_app.py)

```python
import streamlit as st
import asyncio
from dotenv import load_dotenv
import sys
import os

# 경로 설정
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# 환경 변수 로드
load_dotenv()

from src.core.session_manager import SessionManager
from src.core.conversation_manager import ConversationManager
from src.services.ai_service import AIServiceFactory
from src.ui.chat_interface import ChatInterface
from src.ui.sidebar import Sidebar
from src.utils.logger import setup_logger

# 로거 설정
logger = setup_logger(__name__)

# 페이지 설정
st.set_page_config(
    page_title="AI 챗봇",
    page_icon="🤖",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS 스타일
st.markdown("""
    <style>
    .stChat {
        max-width: 1200px;
        margin: 0 auto;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 10px;
        border-radius: 10px;
        margin: 5px 0;
    }
    .assistant-message {
        background-color: #f5f5f5;
        padding: 10px;
        border-radius: 10px;
        margin: 5px 0;
    }
    </style>
""", unsafe_allow_html=True)

class ChatbotApp:
    """메인 챗봇 애플리케이션"""
    
    def __init__(self):
        self.session_manager = SessionManager()
        self.conversation_manager = ConversationManager()
        self.ai_service = None
        self.chat_interface = ChatInterface()
        self.sidebar = Sidebar()
        
    def initialize_session(self):
        """세션 초기화"""
        if 'session_id' not in st.session_state:
            session = self.session_manager.create_session()
            st.session_state.session_id = session.session_id
            st.session_state.messages = []
            st.session_state.current_model = os.getenv("DEFAULT_MODEL", "gpt-3.5-turbo")
            st.session_state.settings = {
                "temperature": 0.7,
                "max_tokens": 2000,
                "stream": True
            }
            logger.info(f"New session created: {session.session_id}")
    
    async def process_message(self, user_input: str):
        """메시지 처리"""
        try:
            # 사용자 메시지 추가
            user_message = await self.conversation_manager.add_user_message(
                st.session_state.session_id,
                user_input
            )
            st.session_state.messages.append(user_message)
            
            # AI 응답 생성
            with st.spinner("생각 중..."):
                if st.session_state.settings.get("stream", True):
                    # 스트리밍 응답
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    async for chunk in self.ai_service.stream_response(
                        messages=st.session_state.messages,
                        settings=st.session_state.settings
                    ):
                        full_response += chunk
                        response_placeholder.markdown(full_response)
                    
                    assistant_message = await self.conversation_manager.add_assistant_message(
                        st.session_state.session_id,
                        full_response
                    )
                else:
                    # 일반 응답
                    response = await self.ai_service.generate_response(
                        messages=st.session_state.messages,
                        settings=st.session_state.settings
                    )
                    assistant_message = response
                    st.markdown(response.content)
            
            st.session_state.messages.append(assistant_message)
            
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            st.error(f"오류가 발생했습니다: {str(e)}")
    
    def run(self):
        """애플리케이션 실행"""
        # 세션 초기화
        self.initialize_session()
        
        # 타이틀
        st.title("🤖 AI 챗봇")
        st.caption("AI와 대화를 나눠보세요!")
        
        # 사이드바 렌더링
        model_type, settings = self.sidebar.render()
        
        if model_type != st.session_state.current_model:
            st.session_state.current_model = model_type
            self.ai_service = AIServiceFactory.create(model_type)
            st.rerun()
        
        st.session_state.settings.update(settings)
        
        # AI 서비스 초기화
        if not self.ai_service:
            self.ai_service = AIServiceFactory.create(st.session_state.current_model)
        
        # 대화 내역 표시
        self.chat_interface.render_conversation(st.session_state.messages)
        
        # 입력 영역
        user_input = self.chat_interface.render_input_area()
        
        if user_input:
            # 비동기 처리
            asyncio.run(self.process_message(user_input))
            st.rerun()

def main():
    """메인 함수"""
    app = ChatbotApp()
    app.run()

if __name__ == "__main__":
    main()
```

### 3.2 AI 서비스 구현

```python
# src/services/ai_service.py
from abc import ABC, abstractmethod
from typing import List, Dict, Generator, Optional
import os
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic

class AIService(ABC):
    """AI 서비스 추상 클래스"""
    
    @abstractmethod
    async def generate_response(
        self, 
        messages: List[Dict],
        settings: Dict
    ) -> str:
        """응답 생성"""
        pass
    
    @abstractmethod
    async def stream_response(
        self,
        messages: List[Dict],
        settings: Dict
    ) -> Generator[str, None, None]:
        """스트리밍 응답 생성"""
        pass

class OpenAIService(AIService):
    """OpenAI 서비스 구현"""
    
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        )
    
    async def generate_response(
        self, 
        messages: List[Dict],
        settings: Dict
    ) -> str:
        """OpenAI 응답 생성"""
        response = await self.client.chat.completions.create(
            model=settings.get("model", "gpt-3.5-turbo"),
            messages=messages,
            temperature=settings.get("temperature", 0.7),
            max_tokens=settings.get("max_tokens", 2000)
        )
        return response.choices[0].message.content
    
    async def stream_response(
        self,
        messages: List[Dict],
        settings: Dict
    ) -> Generator[str, None, None]:
        """OpenAI 스트리밍 응답"""
        stream = await self.client.chat.completions.create(
            model=settings.get("model", "gpt-3.5-turbo"),
            messages=messages,
            temperature=settings.get("temperature", 0.7),
            max_tokens=settings.get("max_tokens", 2000),
            stream=True
        )
        
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content

class ClaudeService(AIService):
    """Claude 서비스 구현"""
    
    def __init__(self):
        self.client = AsyncAnthropic(
            api_key=os.getenv("ANTHROPIC_API_KEY")
        )
    
    async def generate_response(
        self, 
        messages: List[Dict],
        settings: Dict
    ) -> str:
        """Claude 응답 생성"""
        response = await self.client.messages.create(
            model=settings.get("model", "claude-3-sonnet-20240229"),
            messages=messages,
            max_tokens=settings.get("max_tokens", 2000),
            temperature=settings.get("temperature", 0.7)
        )
        return response.content[0].text
    
    async def stream_response(
        self,
        messages: List[Dict],
        settings: Dict
    ) -> Generator[str, None, None]:
        """Claude 스트리밍 응답"""
        async with self.client.messages.stream(
            model=settings.get("model", "claude-3-sonnet-20240229"),
            messages=messages,
            max_tokens=settings.get("max_tokens", 2000),
            temperature=settings.get("temperature", 0.7)
        ) as stream:
            async for text in stream.text_stream:
                yield text

class AIServiceFactory:
    """AI 서비스 팩토리"""
    
    @staticmethod
    def create(model_type: str) -> AIService:
        """모델 타입에 따른 서비스 생성"""
        if model_type.startswith("gpt"):
            return OpenAIService()
        elif model_type.startswith("claude"):
            return ClaudeService()
        else:
            raise ValueError(f"Unsupported model type: {model_type}")
```

### 3.3 UI 컴포넌트 구현

```python
# src/ui/chat_interface.py
import streamlit as st
from typing import List, Dict

class ChatInterface:
    """채팅 인터페이스 컴포넌트"""
    
    def render_conversation(self, messages: List[Dict]):
        """대화 내역 렌더링"""
        for message in messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    def render_input_area(self) -> str:
        """입력 영역 렌더링"""
        return st.chat_input("메시지를 입력하세요...")
    
    def render_typing_indicator(self):
        """타이핑 인디케이터"""
        with st.chat_message("assistant"):
            st.markdown("💭 생각 중...")

# src/ui/sidebar.py
import streamlit as st
from typing import Tuple, Dict

class Sidebar:
    """사이드바 컴포넌트"""
    
    def render(self) -> Tuple[str, Dict]:
        """사이드바 렌더링"""
        with st.sidebar:
            st.header("⚙️ 설정")
            
            # 모델 선택
            model = st.selectbox(
                "AI 모델",
                ["gpt-3.5-turbo", "gpt-4", "claude-3-sonnet", "claude-3-opus"],
                index=0
            )
            
            # 고급 설정
            with st.expander("고급 설정"):
                temperature = st.slider(
                    "Temperature",
                    min_value=0.0,
                    max_value=2.0,
                    value=0.7,
                    step=0.1
                )
                
                max_tokens = st.number_input(
                    "Max Tokens",
                    min_value=100,
                    max_value=4000,
                    value=2000,
                    step=100
                )
                
                stream = st.checkbox("스트리밍 모드", value=True)
            
            # 대화 관리
            st.divider()
            st.header("💬 대화 관리")
            
            if st.button("새 대화 시작", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
            
            if st.button("대화 내역 저장", use_container_width=True):
                # TODO: 구현
                st.success("대화가 저장되었습니다!")
            
            if st.button("대화 내역 불러오기", use_container_width=True):
                # TODO: 구현
                pass
            
            settings = {
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": stream
            }
            
            return model, settings
```

## 4. 배포 방법

### 4.1 로컬 배포

```bash
# 1. 가상환경 생성
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. 패키지 설치
pip install -r requirements.txt

# 3. 환경 변수 설정
cp .env.example .env
# .env 파일에 API 키 입력

# 4. 실행
streamlit run streamlit_app.py
```

### 4.2 Docker 배포

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# 시스템 패키지 설치
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Python 패키지 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 애플리케이션 복사
COPY . .

# 포트 노출
EXPOSE 8501

# 실행 명령
CMD ["streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  chatbot:
    build: .
    ports:
      - "8501:8501"
    env_file:
      - .env
    volumes:
      - ./data:/app/data
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

volumes:
  redis_data:
```

### 4.3 Streamlit Cloud 배포

1. GitHub 저장소 생성 및 코드 푸시
2. [share.streamlit.io](https://share.streamlit.io) 접속
3. GitHub 저장소 연결
4. 환경 변수 설정 (Secrets)
5. 배포

### 4.4 Heroku 배포

```bash
# 1. Heroku CLI 설치
# 2. Procfile 생성
echo "web: sh setup.sh && streamlit run streamlit_app.py" > Procfile

# 3. setup.sh 생성
cat > setup.sh << 'EOF'
mkdir -p ~/.streamlit/

echo "\
[general]\n\
email = \"your-email@domain.com\"\n\
" > ~/.streamlit/credentials.toml

echo "\
[server]\n\
headless = true\n\
enableCORS=false\n\
port = $PORT\n\
" > ~/.streamlit/config.toml
EOF

# 4. Heroku 앱 생성 및 배포
heroku create your-chatbot-app
heroku config:set OPENAI_API_KEY=your-key
git push heroku main
```

## 5. 성능 최적화

### 5.1 캐싱 구현

```python
import streamlit as st
from functools import lru_cache
import hashlib

@st.cache_data(ttl=3600)
def get_cached_response(prompt_hash: str) -> str:
    """캐시된 응답 조회"""
    # 데이터베이스에서 캐시 조회
    pass

@lru_cache(maxsize=100)
def calculate_prompt_hash(prompt: str) -> str:
    """프롬프트 해시 계산"""
    return hashlib.md5(prompt.encode()).hexdigest()
```

### 5.2 비동기 처리

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor(max_workers=4)

async def process_batch_messages(messages: List[str]):
    """배치 메시지 처리"""
    tasks = [process_single_message(msg) for msg in messages]
    return await asyncio.gather(*tasks)
```

## 6. 테스트

### 6.1 단위 테스트

```python
# tests/test_services/test_ai_service.py
import pytest
from unittest.mock import Mock, AsyncMock
from src.services.ai_service import OpenAIService

@pytest.mark.asyncio
async def test_generate_response():
    """응답 생성 테스트"""
    service = OpenAIService()
    service.client = Mock()
    service.client.chat.completions.create = AsyncMock(
        return_value=Mock(
            choices=[Mock(message=Mock(content="Test response"))]
        )
    )
    
    response = await service.generate_response(
        messages=[{"role": "user", "content": "Hello"}],
        settings={"model": "gpt-3.5-turbo"}
    )
    
    assert response == "Test response"
```

### 6.2 통합 테스트

```python
# tests/test_integration.py
import pytest
from streamlit.testing.v1 import AppTest

def test_chatbot_app():
    """챗봇 앱 통합 테스트"""
    at = AppTest.from_file("streamlit_app.py")
    at.run()
    
    # 초기 상태 확인
    assert not at.exception
    assert at.title[0].value == "🤖 AI 챗봇"
    
    # 메시지 입력 테스트
    at.chat_input[0].set_value("Hello").run()
    assert len(at.chat_message) > 0
```

## 7. 모니터링 및 로깅

### 7.1 로깅 설정

```python
# src/utils/logger.py
import logging
import sys
from logging.handlers import RotatingFileHandler

def setup_logger(name: str) -> logging.Logger:
    """로거 설정"""
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    # 콘솔 핸들러
    console_handler = logging.StreamHandler(sys.stdout)
    console_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(console_formatter)
    
    # 파일 핸들러
    file_handler = RotatingFileHandler(
        'chatbot.log',
        maxBytes=10485760,  # 10MB
        backupCount=5
    )
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
    )
    file_handler.setFormatter(file_formatter)
    
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    
    return logger
```

## 8. 보안 고려사항

### 8.1 API 키 관리

```python
# src/utils/encryption.py
from cryptography.fernet import Fernet
import os

class SecureStorage:
    """보안 저장소"""
    
    def __init__(self):
        key = os.getenv("ENCRYPTION_KEY")
        if not key:
            key = Fernet.generate_key()
        self.cipher = Fernet(key)
    
    def encrypt_api_key(self, api_key: str) -> bytes:
        """API 키 암호화"""
        return self.cipher.encrypt(api_key.encode())
    
    def decrypt_api_key(self, encrypted_key: bytes) -> str:
        """API 키 복호화"""
        return self.cipher.decrypt(encrypted_key).decode()
```

### 8.2 입력 검증

```python
# src/utils/validators.py
import re
from typing import Tuple

def validate_user_input(text: str) -> Tuple[bool, str]:
    """사용자 입력 검증"""
    # 길이 체크
    if len(text) > 10000:
        return False, "메시지가 너무 깁니다."
    
    # XSS 방지
    if re.search(r'<script|javascript:', text, re.IGNORECASE):
        return False, "허용되지 않는 내용이 포함되어 있습니다."
    
    # SQL 인젝션 방지
    if re.search(r"(DROP|DELETE|INSERT|UPDATE)\s+", text, re.IGNORECASE):
        return False, "허용되지 않는 SQL 명령이 포함되어 있습니다."
    
    return True, ""
```

## 9. 확장 기능

### 9.1 RAG (Retrieval-Augmented Generation) 지원

```python
# src/services/rag_service.py
from typing import List
import chromadb

class RAGService:
    """RAG 서비스"""
    
    def __init__(self):
        self.client = chromadb.Client()
        self.collection = self.client.create_collection("documents")
    
    async def add_document(self, text: str, metadata: dict):
        """문서 추가"""
        embedding = await self.generate_embedding(text)
        self.collection.add(
            embeddings=[embedding],
            documents=[text],
            metadatas=[metadata]
        )
    
    async def search_similar(self, query: str, n_results: int = 5):
        """유사 문서 검색"""
        query_embedding = await self.generate_embedding(query)
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )
        return results
```

### 9.2 다국어 지원

```python
# src/utils/i18n.py
translations = {
    "ko": {
        "welcome": "AI 챗봇에 오신 것을 환영합니다!",
        "enter_message": "메시지를 입력하세요...",
        "settings": "설정",
        "new_chat": "새 대화 시작"
    },
    "en": {
        "welcome": "Welcome to AI Chatbot!",
        "enter_message": "Enter your message...",
        "settings": "Settings",
        "new_chat": "Start New Chat"
    }
}

def get_text(key: str, lang: str = "ko") -> str:
    """번역된 텍스트 가져오기"""
    return translations.get(lang, {}).get(key, key)
```

## 10. 문제 해결 가이드

### 10.1 일반적인 문제

| 문제 | 원인 | 해결 방법 |
|------|------|-----------|
| API 키 오류 | 잘못된 키 또는 만료 | .env 파일 확인 및 키 재발급 |
| 느린 응답 | 네트워크 또는 모델 이슈 | 캐싱 활성화, 모델 변경 |
| 세션 손실 | 서버 재시작 | Redis 등 영구 저장소 사용 |
| 메모리 부족 | 대화 내역 과다 | 컨텍스트 윈도우 제한 |

### 10.2 디버깅 팁

```python
# 디버깅 모드 활성화
if os.getenv("APP_ENV") == "development":
    st.sidebar.json(st.session_state)  # 세션 상태 표시
    
# 성능 프로파일링
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()
# 코드 실행
profiler.disable()
stats = pstats.Stats(profiler)
stats.print_stats()
```